{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import json\n",
    "import time\n",
    "from datetime import timedelta\n",
    "\n",
    "from temporalcontext import settings\n",
    "from temporalcontext.functions import read_selmap, read_folds_info, \\\n",
    "    get_lstm_model_filename, gen_list_of_section_files, \\\n",
    "    LSTMData, chunk_up, lstm_predict\n",
    "\n",
    "\n",
    "hybrid_types = ['t1', 't2', 't3']\n",
    "\n",
    "output_filename_fmt = 'scores_TS{:d}_PP{:d}.json'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "selmap = read_selmap(os.path.join(settings.raw_data_root, 'selmap.csv'))\n",
    "fold_file_idxs = read_folds_info(os.path.join(settings.raw_data_root, 'folds_info.txt'))\n",
    "\n",
    "for fold_idx, fold_info in enumerate(fold_file_idxs):\n",
    "\n",
    "    for lstm_exp in settings.lstm_experiments:\n",
    "        print('---------- Fold {:02d}, segment_advance={:.2f}, PP={:d} ----------'.format(\n",
    "            fold_idx + 1, lstm_exp['segment_advance'], lstm_exp['pp']))\n",
    "        \n",
    "        fold_seg_root = os.path.join(settings.project_root, settings.folds_dir,\n",
    "                                     'f{:02d}'.format(fold_idx + 1),\n",
    "                                     'seg_adv_{:.2f}'.format(lstm_exp['segment_advance']))\n",
    "        input_root = os.path.join(fold_seg_root, settings.lstm_data_dir)\n",
    "        model_dir = os.path.join(fold_seg_root, settings.models_dir)\n",
    "        scores_root = os.path.join(fold_seg_root, settings.scores_dir)\n",
    "        \n",
    "        tf.keras.backend.clear_session()\n",
    "\n",
    "        # Load hybrid models\n",
    "        lstm_models = list()\n",
    "        for m_type in hybrid_types:\n",
    "            model_filepath = \\\n",
    "                os.path.join(model_dir,\n",
    "                             get_lstm_model_filename(\n",
    "                                 m_type, lstm_exp['time_steps'], lstm_exp['pp']))\n",
    "            lstm_models.append(None if not os.path.exists(model_filepath)\n",
    "                               else tf.keras.models.load_model(model_filepath))\n",
    "        \n",
    "        # Placeholders for collecting detection scores\n",
    "        per_file_scores = dict()\n",
    "        score_ranges = {m_type: [math.inf, -math.inf]\n",
    "                        for m_type in ['cnn'] + hybrid_types}\n",
    "        num_samples = 0\n",
    "        process_time = 0.0\n",
    "        \n",
    "        # Process each valid test file\n",
    "        for sec_file in gen_list_of_section_files(input_root,\n",
    "                                                  [selmap[f_idx][0] for f_idx in fold_info['test']],\n",
    "                                                  settings.section_suffixes):\n",
    "            \n",
    "            # Load data\n",
    "            _, _, t1_input, t2_input, _, _ = LSTMData.read(sec_file,\n",
    "                                                           lstm_exp['time_steps'],\n",
    "                                                           lstm_exp['pp'])\n",
    "            \n",
    "            if t1_input.shape[0] < lstm_exp['time_steps']:\n",
    "                continue\n",
    "                \n",
    "            num_samples += t1_input.shape[0]\n",
    "            \n",
    "            # Gather scores\n",
    "            per_model_scores = dict()\n",
    "            \n",
    "            # CNN scores. Model was already run; just collect stored scores\n",
    "            m_type = 'cnn'\n",
    "            _, scores = chunk_up(t1_input, t1_input[:, 0],\n",
    "                                   lstm_exp['time_steps'], lstm_exp['pp'])\n",
    "            per_model_scores[m_type] = scores.tolist()\n",
    "            score_ranges[m_type][0] = min(score_ranges[m_type][0], float(scores.min()))\n",
    "            score_ranges[m_type][1] = max(score_ranges[m_type][1], float(scores.max()))\n",
    "            \n",
    "            # Hybrid models' scores. Run each detector\n",
    "            start_time = time.time()\n",
    "            for m_type, lstm_model, lstm_data in zip(hybrid_types,\n",
    "                                                      lstm_models,\n",
    "                                                      [t1_input, t2_input, np.concatenate([t1_input, t2_input], axis=1)]):\n",
    "                \n",
    "                if lstm_model is None:\n",
    "                    per_model_scores[m_type] = []\n",
    "                    continue\n",
    "                \n",
    "                scores = lstm_predict(lstm_model, lstm_data, lstm_exp['time_steps'], lstm_exp['pp'])\n",
    "                \n",
    "                per_model_scores[m_type] = scores.tolist()\n",
    "                score_ranges[m_type][0] = min(score_ranges[m_type][0], float(scores.min()))\n",
    "                score_ranges[m_type][1] = max(score_ranges[m_type][1], float(scores.max()))\n",
    "            end_time = time.time()\n",
    "            \n",
    "            # Gather file-level results\n",
    "            per_file_scores[sec_file[len(input_root) + 1:]] = per_model_scores\n",
    "            del per_model_scores\n",
    "            process_time += (end_time - start_time)\n",
    "        \n",
    "        del lstm_models\n",
    "            \n",
    "        # Save results\n",
    "        os.makedirs(scores_root, exist_ok=True)\n",
    "        json.dump(\n",
    "            dict(scores=per_file_scores,\n",
    "                 score_ranges=score_ranges),\n",
    "            open(os.path.join(scores_root,\n",
    "                              output_filename_fmt.format(lstm_exp['time_steps'], lstm_exp['pp'])),\n",
    "                 'w')\n",
    "        )\n",
    "\n",
    "        del per_file_scores\n",
    "\n",
    "        print('Num samples  : {:d}'.format(num_samples))\n",
    "        print('Score ranges - ')\n",
    "        for m_type in ['cnn'] + hybrid_types:\n",
    "            print('{:5s}: [{:.4f}. {:.4f}]'.format(m_type,\n",
    "                                                   score_ranges[m_type][0],\n",
    "                                                   score_ranges[m_type][1]))\n",
    "        print('Processed in {}'.format(timedelta(seconds=process_time)))\n",
    "        print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
