{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import soundfile as sf\n",
    "from temporalcontext import settings\n",
    "from temporalcontext.functions import read_selmap, read_folds_info, \\\n",
    "    load_annotations, load_audio_as_segments, segments2specgrams, \\\n",
    "    LSTMData, song_section_selections, non_song_section_selections, \\\n",
    "    get_testing_cnn_model, cnn_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create fold-specific data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# The root directory under which audio & corresponding annotation files are\n",
    "# available\n",
    "audio_root = os.path.join(settings.raw_data_root, settings.raw_audio_dir)\n",
    "seltab_root = os.path.join(settings.raw_data_root, settings.raw_annot_dir)\n",
    "\n",
    "selmap = read_selmap(os.path.join(settings.raw_data_root, 'selmap.csv'))\n",
    "fold_file_idxs = read_folds_info(os.path.join(settings.raw_data_root, 'folds_info.txt'))\n",
    "\n",
    "# Loop over each unique segment advance setting\n",
    "for seg_adv, time_step in list(set([(ex['segment_advance'], ex['time_steps']) for ex in settings.lstm_experiments])):\n",
    "\n",
    "    tracks_summary = np.zeros((len(fold_file_idxs), 2), dtype=np.uint64)\n",
    "    \n",
    "    for fold_idx in range(len(fold_file_idxs)):\n",
    "        \n",
    "        fold_seg_root = os.path.join(settings.project_root, settings.folds_dir,\n",
    "                                     'f{:02d}'.format(fold_idx + 1),\n",
    "                                     'seg_adv_{:.2f}'.format(seg_adv))\n",
    "        \n",
    "        print('Fold {:02d}, segment advance={:.2f} s'.format(fold_idx + 1, seg_adv))\n",
    "\n",
    "        tf.keras.backend.clear_session()\n",
    "\n",
    "        # Load the CNN model\n",
    "        model_path = os.path.join(fold_seg_root, settings.models_dir, 'baseCNN.h5')\n",
    "        cnn_model = get_testing_cnn_model(model_path)\n",
    "\n",
    "        # Output root\n",
    "        output_root = os.path.join(fold_seg_root, settings.lstm_data_dir)\n",
    "\n",
    "        # Run model on all data files and save the outputs\n",
    "        for audio_file, pos_annot_file, neg_annot_file in selmap:\n",
    "\n",
    "            # Get audio_file duration\n",
    "            file_dur = sf.info(os.path.join(audio_root, audio_file)).duration\n",
    "\n",
    "            # ---------- Song sections ----------\n",
    "            print('    {:s}: '.format(pos_annot_file), end='')\n",
    "\n",
    "            selections = load_annotations(os.path.join(seltab_root, pos_annot_file))\n",
    "            section_start_ends, song_start_end_sel_idxs = \\\n",
    "                song_section_selections(selections, file_dur,\n",
    "                                        settings.max_call_separation,\n",
    "                                        settings.min_calls_in_song,\n",
    "                                        time_step * seg_adv)\n",
    "\n",
    "            print('{:d} sections'.format(section_start_ends.shape[0]), end='')\n",
    "            # print(section_start_ends)\n",
    "\n",
    "            if section_start_ends.shape[0] > 0:\n",
    "                \n",
    "                tracks_summary[fold_idx, 0] += section_start_ends.shape[0]\n",
    "                total_segs = 0\n",
    "\n",
    "                for sec_idx, (sec_start, sec_end) in enumerate(section_start_ends):\n",
    "\n",
    "                    # Load song section from audio file\n",
    "                    segments, segment_starts, fs = load_audio_as_segments(\n",
    "                        os.path.join(audio_root, audio_file),\n",
    "                        settings.segment_length, seg_adv,\n",
    "                        extents=[sec_start, sec_end])\n",
    "                    segments = segments2specgrams(segments, fs, settings.specgram_params, settings.bandwidth_extents)\n",
    "\n",
    "                    # Determine 'fully contained' overlaps with annotations and\n",
    "                    # score positives as 1 & negatives as 0\n",
    "\n",
    "                    sec_seg_idxs = np.arange(song_start_end_sel_idxs[sec_idx, 0],\n",
    "                                             song_start_end_sel_idxs[sec_idx, 1] + 1)\n",
    "                    # print('Num sel  :', len(sec_seg_idxs), '[', sec_seg_idxs[0], '-', sec_seg_idxs[-1], ']')\n",
    "                    # print('Sel :', selections[sec_seg_idxs[0], 0], selections[sec_seg_idxs[-1], 1])\n",
    "                    y = np.stack([\n",
    "                        np.logical_and(\n",
    "                            seg_s <= selections[sec_seg_idxs, 0],\n",
    "                            seg_e >= selections[sec_seg_idxs, 1])\n",
    "                        for seg_s, seg_e in zip(segment_starts, segment_starts + settings.segment_length)]\n",
    "                    ).any(axis=1)\n",
    "\n",
    "                    # Run CNN model on section's segments\n",
    "                    cnn_scores, cnn_fcns = cnn_predict(cnn_model, np.expand_dims(segments, axis=3))\n",
    "\n",
    "                    # save to file\n",
    "                    output_file = os.path.join(\n",
    "                        output_root,\n",
    "                        os.path.splitext(audio_file)[0] + settings.section_suffixes[0] + '{:02d}.npz'.format(sec_idx + 1))\n",
    "                    os.makedirs(os.path.split(output_file)[0], exist_ok=True)\n",
    "                    LSTMData.write(output_file,\n",
    "                                   sec_start, sec_end, cnn_scores, cnn_fcns, y,\n",
    "                                   selections)\n",
    "\n",
    "                    total_segs += segments.shape[0]\n",
    "\n",
    "                print(', {:d} segments'.format(total_segs))\n",
    "                \n",
    "            else:\n",
    "                print()\n",
    "\n",
    "\n",
    "            # ---------- Non-song sections ----------\n",
    "            print('    {:s}: '.format(neg_annot_file), end='')\n",
    "\n",
    "            selections = load_annotations(os.path.join(seltab_root, neg_annot_file))\n",
    "            section_start_ends = non_song_section_selections(selections,\n",
    "                                                             settings.min_non_song_duration)\n",
    "\n",
    "            print('{:d} sections'.format(section_start_ends.shape[0]), end='')\n",
    "            # print(section_start_ends)\n",
    "\n",
    "            if section_start_ends.shape[0] > 0:\n",
    "                \n",
    "                tracks_summary[fold_idx, 1] += section_start_ends.shape[0]\n",
    "                total_segs = 0\n",
    "\n",
    "                for sec_idx, (sec_start, sec_end) in enumerate(section_start_ends):\n",
    "\n",
    "                    # Load segment from audio file\n",
    "                    segments, segment_starts, fs = load_audio_as_segments(\n",
    "                        os.path.join(audio_root, audio_file),\n",
    "                        settings.segment_length, seg_adv,\n",
    "                        extents=[sec_start, sec_end])\n",
    "                    segments = segments2specgrams(segments, fs, settings.specgram_params, settings.bandwidth_extents)\n",
    "\n",
    "                    # Everything will be zero\n",
    "                    y = np.zeros((segments.shape[0], ))\n",
    "\n",
    "                    # Run CNN model on segment\n",
    "                    cnn_scores, cnn_fcns = cnn_predict(cnn_model, np.expand_dims(segments, axis=3))\n",
    "\n",
    "                    # save to file\n",
    "                    output_file = os.path.join(\n",
    "                        output_root,\n",
    "                        os.path.splitext(audio_file)[0] + settings.section_suffixes[1] + '{:02d}.npz'.format(sec_idx + 1))\n",
    "                    os.makedirs(os.path.split(output_file)[0], exist_ok=True)\n",
    "                    LSTMData.write(output_file,\n",
    "                                   sec_start, sec_end, cnn_scores, cnn_fcns, y, None)\n",
    "\n",
    "                    total_segs += segments.shape[0]\n",
    "\n",
    "                print(', {:d} segments'.format(total_segs))\n",
    "                \n",
    "            else:\n",
    "                print()\n",
    "        \n",
    "        del cnn_model\n",
    "\n",
    "        print('------------------------------------------------------------')\n",
    "    print('Summary for segment advance {:.2f} s'.format(seg_adv))\n",
    "    for fold_idx in range(len(fold_file_idxs)):\n",
    "        print('  Fold {:02d}: {:7d} song sections, {:7d} non-song sections'.format(\n",
    "            fold_idx + 1, tracks_summary[fold_idx, 0], tracks_summary[fold_idx, 1]))\n",
    "    print('============================================================')\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
